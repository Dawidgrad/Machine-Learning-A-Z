{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data.csv')\n",
    "independent_variables = dataset.iloc[:, :-1].values\n",
    "dependent_variables = dataset.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking care of the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(independent_variables[:, 1:3])\n",
    "independent_variables[:, 1:3] = imputer.transform(independent_variables[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "encoder_country = LabelEncoder()\n",
    "independent_variables[:, 0] = encoder_country.fit_transform(independent_variables[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "independent_variables = onehotencoder.fit_transform(independent_variables).toarray()\n",
    "\n",
    "# Dependent variable does not need a OneHotEncoder since the machine learning \n",
    "# model will know it's a category and there is not order between the two\n",
    "encoder_purchased = LabelEncoder()\n",
    "dependent_variables = encoder_purchased.fit_transform(dependent_variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the formatting and display the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1.00,     0.00,     0.00,    44.00, 72000.00],\n",
       "       [    0.00,     0.00,     1.00,    27.00, 48000.00],\n",
       "       [    0.00,     1.00,     0.00,    30.00, 54000.00],\n",
       "       [    0.00,     0.00,     1.00,    38.00, 61000.00],\n",
       "       [    0.00,     1.00,     0.00,    40.00, 63777.78],\n",
       "       [    1.00,     0.00,     0.00,    35.00, 58000.00],\n",
       "       [    0.00,     0.00,     1.00,    38.78, 52000.00],\n",
       "       [    1.00,     0.00,     0.00,    48.00, 79000.00],\n",
       "       [    0.00,     1.00,     0.00,    50.00, 83000.00],\n",
       "       [    1.00,     0.00,     0.00,    37.00, 67000.00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision = 2, floatmode = 'fixed', suppress = True)\n",
    "independent_variables #dependent_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "independent_train, independent_test, dependent_train, dependent_test \\\n",
    "    = train_test_split(independent_variables, dependent_variables, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_independent = StandardScaler()\n",
    "\n",
    "# Scaling the dummy variables is not always needed as you lose some interpretation \n",
    "# but it will be done for the sake of the tutorial\n",
    "independent_train = scaler_independent.fit_transform(independent_train)\n",
    "independent_test = scaler_independent.transform(independent_test)\n",
    "\n",
    "# The scaler was fitted to train set and not to test set\n",
    "# because we want them both to have same value range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "371px",
    "left": "960px",
    "right": "20px",
    "top": "122px",
    "width": "606px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
